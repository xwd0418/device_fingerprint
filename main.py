from models.PL_resnet import * 
from models.PL_MMD_AAE import *
from models.PL_ConDG import *
import torch._inductor.config as torch_config
import json, shutil
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.callbacks import LearningRateMonitor, StochasticWeightAveraging
from pytorch_lightning.loggers import TensorBoardLogger
# from pytorch_lightning.strategies import DDPSpawnStrategy
# from pytorch_lightning.tuner import Tuner
import optuna
from optuna.integration import PyTorchLightningPruningCallback
from data_module import DeviceFingerpringDataModule

def objective(trial: optuna.trial.Trial) -> float:
    if len(sys.argv) > 1:
        exp_name = sys.argv[1]
    override_name = None
    if len(sys.argv) > 2:
        override_name = sys.argv[2]
    # version = None
    name, version = exp_name.split('/')
    # name=name+"_new_loader"
    if override_name:
        name = "dev"  
    # os.makedirs(os.path.join(log_dir,name,version), exist_ok=True)   
    # shutil.copy2(config_file_path,os.path.join(log_dir,name+"_new_loader",version))
    config_file_path = f'/root/configs_optuna/'+ exp_name + '.json'
    f = open(config_file_path)        
    config = json.load(f)
    

    sample_config(trial, config)
    
    if config['model']['name'] == "MMD_AAE":
        n_layers = config['model'].get('adv_layer_nums')
        if n_layers:
            config['model']['hidden_units_size'] = [
                trial.suggest_int(f"adv_units_l{i+1}", config['model']['adv_hidden_size_range'][0],
                                config['model']['adv_hidden_size_range'][1]  , log=True) for i in range(n_layers)
            ]  
        
    if config['model']['name'] == "ConDG":
        general_n_layers = config['model'].get('general_layer_nums')
        if general_n_layers:
            config['model']['general_hidden_units_size'] = [
                trial.suggest_int(f"general_layers_units_l{i+1}", config['model']['general_hidden_size_range'][0],
                                config['model']['general_hidden_size_range'][1], log=True) for i in range(general_n_layers)
            ]  
        
        con_n_layers = config['model'].get('con_layer_nums')
        if con_n_layers:
            config['model']['con_hidden_units_size'] = [
                trial.suggest_int(f"con_layers_units_l{i+1}", config['model']['con_hidden_size_range'][0],
                                config['model']['con_hidden_size_range'][1], log=True) for i in range(con_n_layers)
            ]  
            
        if config['experiment']['discrepency_metric'] == "MMD":
            low,high = config['experiment']['MMD_sample_size']
            config['experiment']['MMD_sample_size'] = trial.suggest_int("MMD_sample_size", low, high, log=True)
            
       
        
    datamodule = DeviceFingerpringDataModule(config = config)
    # Init our model
    if config['model']['name'] == 'resnet18':
        model = Baseline_Resnet(config)
    if config['model']['name'] == 'MMD_AAE':
        model = MMD_AAE(config)  
    if config['model']['name'] == 'ConDG':
        model = ConDG(config, datamodule)  
        
    
            
    
    # model.giant_batch_size = len(datamodule.df_data_train)//config['dataset']['batch_size'] < 50
    
        
    '''callbacks'''
    checkpoint_callback = PL.callbacks.ModelCheckpoint(monitor="val/loss", mode="min", save_last=False, save_weights_only=False)
    # early_stop_callback = EarlyStopping(monitor="val/loss", mode="min", patience=10)
    lr_monitor_callback = LearningRateMonitor(logging_interval='step')
    # prune_callback = PyTorchLightningPruningCallback(trial, monitor="val/acc")
    # swa_callback = StochasticWeightAveraging(swa_lrs=1e-2)
    log_dir = f'/root/exps_autotune/' 
    os.makedirs(log_dir, exist_ok=True)


    # Initialize a trainer
    max_epoch = 2  if len(sys.argv) > 2 else 500
    
    if torch.cuda.device_count() < 2:
        strategy = 'auto'  
    elif config['model']['name'] == 'ConDG':
        strategy = 'ddp_spawn_find_unused_parameters_true'
    else:    
        strategy = 'ddp_spawn'
    print("using strategy: ", strategy)
    
    version = version+f"/trail{trial.number}"
    trial.set_user_attr("logging_path",os.path.join(log_dir,name,version))
    trainer = PL.Trainer(
        accelerator="gpu",
        devices=1,
        # devices=torch.cuda.device_count(),
        # strategy = strategy,
        max_epochs = max_epoch,
        logger=CSVLogger          (save_dir=log_dir, name=name, version=version),
        # logger = TensorBoardLogger(save_dir=log_dir, name=name, version=version),
        callbacks=[checkpoint_callback,
                #    early_stop_callback, 
                   lr_monitor_callback,
                #    prune_callback
                   ],
        # reload_dataloaders_every_n_epochs=1,
        # log_every_n_steps=40
        # profiler="advanced",
    )
    # tuner = Tuner(trainer)
    # tuner.scale_batch_size(model, mode="power")
    # torch_config.compile_threads = 1
    # model = torch.compile(model, mode="reduce-overhead")
    hyperparameters = config
    trainer.logger.log_hyperparams(hyperparameters)
    # Train the model âš¡
    trainer.fit(model, datamodule=datamodule)
    # print("trainer.callback_metrics ",trainer.callback_metrics)   
    # prune_callback.check_pruned()
    trainer.test(ckpt_path='best', datamodule=datamodule )  
    return trainer.callback_metrics["test/acc"].item()

def sample_config(trial, config):
    '''set up optuna's guessing'''    
    for k, v in config.items():
        if type(v) == dict:
            sample_config(trial,v)
        if type(v) == list and v[0] == "optuna": # should change it to optuna guessing
            if type(v[1]) == str:
                config[k] = trial.suggest_categorical(k, v[1:])
            elif type(v[1]) == int:
                log, step = False, 1
                if type(v[-1]) == str:
                    if v[-1] == "log": 
                        log = True
                    else:
                        assert(v[-1].split("=")[0]=="step")
                        step = int(v[-1].split("=")[1])
                config[k] = trial.suggest_int(k, v[1], v[2], log=log, step=step)
            elif type(v[1]) == float:
                log, step = False, None
                if type(v[-1]) == str:
                    if v[-1] == "log": 
                        log = True
                    else:
                        assert(v[-1].split("=")[0]=="step")
                        step = float(v[-1].split("=")[1])
                config[k] = trial.suggest_float(k, v[1], v[2], log=log, step=step)
                

def delete_bad_ckpt_callback(study, trial):
    print("current trial.value: ", trial.value)
    print("study.best_value: ",study.best_value)
    path = trial.user_attrs["logging_path"]
    # print("trial logging path: ", path)
    if  trial.number <= 25 or trial.value< max(study.best_value, 0.6):
        os.system(f'rm -r {path}')
    # if study.best_trial.number != trial.number:
    #     study.set_user_attr(key="best_booster", value=trial.user_attrs["best_booster"])    
        
                               
if __name__ == "__main__":
    os.system('nvidia-smi -L')
    print("cpu count: ", os.cpu_count())
    torch.set_float32_matmul_precision("medium")
    # torch._dynamo.config.suppress_errors = True
    
    seed = 3407
    np.random.seed(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    if len(sys.argv) > 1:
        exp_name = sys.argv[1]

    print("Running Experiment: ", exp_name)
    config_file_path = f'/root/configs_optuna/'+ exp_name + '.json'
    f = open(config_file_path)        
    config = json.load(f)
            
    # pruner = optuna.pruners.NopPruner() if config.get('no_prune') else \
    #     optuna.pruners.MedianPruner(n_warmup_steps=12,interval_steps=2)

   
    # storage = "mysql+mysqlconnector://root:test1234@10.244.198.163:3306/ddp_database"
    storage = "postgresql+psycopg2://testUser:testPassword@10.244.118.123:5432/testDB"
    print("creating a new study")
    if  len(sys.argv) > 2:
        study_name = "dev"  
    elif 'resnet' in exp_name:
        study_name = exp_name  
    else:
        study_name = "pretrained_"+exp_name
    study = optuna.create_study(
        study_name=study_name,
        storage=storage,
        direction="maximize",
        # pruner=pruner,
        load_if_exists=True, 
    )
    study.optimize(objective, n_trials=100, callbacks=[delete_bad_ckpt_callback])
    

    print("Number of finished trials: {}".format(len(study.trials)))

    print("Best trial:")
    trial = study.best_trial

    print("  Value: {}".format(trial.value))

    print("  Params: ")
    for key, value in trial.params.items():
        print("    {}: {}".format(key, value))
