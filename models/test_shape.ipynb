{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PL_MMD_AAE import *\n",
    "import json\n",
    "exp_name = 'MMD_AAE/v1'\n",
    "exp_name = 'resnet/resnet18_v1'\n",
    "f = open(f'/root/configs/'+ exp_name + '.json')\n",
    "        # f = open(f'/root/autoencoder_denoiser/configs_baseline_selection/'+ name + '.json')\n",
    "        # global config\n",
    "        \n",
    "config = json.load(f)\n",
    "model = MMD_AAE(config)\n",
    "\n",
    "input = torch.rand([16,2,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.encoder.avgpool = nn.AdaptiveAvgPool1d(output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit, output_feature = model(input, feat = True)\n",
    "output_feature.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  model_factory import *\n",
    "# up1 = Up(in_channels=512, out_channels= 256, linear= True)\n",
    "# f1 = up1(output_feature)\n",
    "decoder = Decoder(256, 2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = decoder(output_feature)\n",
    "f1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'up1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52152/2678017477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mup1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'up1' is not defined"
     ]
    }
   ],
   "source": [
    "f2 = up1.conv.double_conv(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf\n"
     ]
    }
   ],
   "source": [
    "a = 0.23423\n",
    "if a:\n",
    "    print(\"sdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00193045, 0.04393693, 0.00193045],\n",
       "       [0.04393693, 1.        , 0.04393693],\n",
       "       [0.00193045, 0.04393693, 0.00193045]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import np as np\n",
    "def fspecial_gauss(size, sigma):\n",
    "\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g\n",
    "fspecial_gauss(3, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07511361, 0.1238414 , 0.07511361],\n",
       "       [0.1238414 , 0.20417996, 0.1238414 ],\n",
       "       [0.07511361, 0.1238414 , 0.07511361]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2239, 0.0379, 0.2276],\n",
       "          [0.5059, 0.0491, 0.8847],\n",
       "          [0.7270, 0.9974, 0.7017]]],\n",
       "\n",
       "\n",
       "        [[[0.3196, 0.6913, 0.9985],\n",
       "          [0.5852, 0.5522, 0.3204],\n",
       "          [0.5309, 0.8884, 0.2540]]],\n",
       "\n",
       "\n",
       "        [[[0.9782, 0.5833, 0.5246],\n",
       "          [0.9165, 0.0190, 0.7923],\n",
       "          [0.2905, 0.0981, 0.8100]]],\n",
       "\n",
       "\n",
       "        [[[0.0870, 0.2357, 0.6431],\n",
       "          [0.6904, 0.8649, 0.6228],\n",
       "          [0.4813, 0.7829, 0.7411]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision, torch\n",
    "num_channels = 1\n",
    "conv = torchvision.ops.DeformConv2d(in_channels=num_channels, out_channels=num_channels, kernel_size=3, padding=1)\n",
    "a = torch.rand((4,1,3,3))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# offset = torch.tensor([\n",
    "#     [0,0,0],\n",
    "#     [0,0,0],\n",
    "#     [0,0,0]\n",
    "# ])\n",
    "offset = torch.rand((4,2*3*3,3,3))\n",
    "conv(a, offset=offset,).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.fftpack\n",
    "\n",
    "\n",
    "def fftind(size):\n",
    "    \"\"\" Returns a np array of shifted Fourier coordinates k_x k_y.\n",
    "        \n",
    "        Input args:\n",
    "            size (integer): The size of the coordinate array to create\n",
    "        Returns:\n",
    "            k_ind, np array of shape (2, size, size) with:\n",
    "                k_ind[0,:,:]:  k_x components\n",
    "                k_ind[1,:,:]:  k_y components\n",
    "                \n",
    "        Example:\n",
    "        \n",
    "            print(fftind(5))\n",
    "            \n",
    "            [[[ 0  1 -3 -2 -1]\n",
    "            [ 0  1 -3 -2 -1]\n",
    "            [ 0  1 -3 -2 -1]\n",
    "            [ 0  1 -3 -2 -1]\n",
    "            [ 0  1 -3 -2 -1]]\n",
    "\n",
    "            [[ 0  0  0  0  0]\n",
    "            [ 1  1  1  1  1]\n",
    "            [-3 -3 -3 -3 -3]\n",
    "            [-2 -2 -2 -2 -2]\n",
    "            [-1 -1 -1 -1 -1]]]\n",
    "            \n",
    "        \"\"\"\n",
    "    k_ind = np.mgrid[:size, :size] - int( (size + 1)/2 )\n",
    "    k_ind = scipy.fftpack.fftshift(k_ind)\n",
    "    return( k_ind )\n",
    "\n",
    "def gaussian_random_field(alpha = 10.0,\n",
    "                          size = 3, \n",
    "                          flag_normalize = True):\n",
    "    \"\"\" Returns a np array of shifted Fourier coordinates k_x k_y.\n",
    "        \n",
    "        Input args:\n",
    "            alpha (double, default = 3.0): \n",
    "                The power of the power-law momentum distribution\n",
    "            size (integer, default = 128):\n",
    "                The size of the square output Gaussian Random Fields\n",
    "            flag_normalize (boolean, default = True):\n",
    "                Normalizes the Gaussian Field:\n",
    "                    - to have an average of 0.0\n",
    "                    - to have a standard deviation of 1.0\n",
    "\n",
    "        Returns:\n",
    "            gfield (np array of shape (size, size)):\n",
    "                The random gaussian random field\n",
    "                \n",
    "        Example:\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "        example = gaussian_random_field()\n",
    "        plt.imshow(example)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Defines momentum indices\n",
    "    k_idx = fftind(size)\n",
    "\n",
    "        # Defines the amplitude as a power law 1/|k|^(alpha/2)\n",
    "    amplitude = np.power( k_idx[0]**2 + k_idx[1]**2 + 1e-10, -alpha/4.0 )\n",
    "    amplitude[0,0] = 0\n",
    "    \n",
    "        # Draws a complex gaussian random noise with normal\n",
    "        # (circular) distribution\n",
    "    noise = np.random.normal(size = (size, size)) \\\n",
    "        + 1j * np.random.normal(size = (size, size))\n",
    "    \n",
    "        # To real space\n",
    "    gfield = np.fft.ifft2(noise * amplitude).real\n",
    "    \n",
    "        # Sets the standard deviation to one\n",
    "    if flag_normalize:\n",
    "        gfield = gfield - np.mean(gfield)\n",
    "        gfield = gfield/np.std(gfield)\n",
    "        \n",
    "    return gfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "example = gaussian_random_field()\n",
    "plt.imshow(example, cmap='gray')\n",
    "plt.show()\n",
    "example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.51048075, -1.3591392 , -0.83406963],\n",
       "       [ 0.54100506, -1.15942948, -0.56067401],\n",
       "       [ 1.93702543,  0.28148159,  0.64331949]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9, 3, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GRF_wrapper(a):\n",
    "    return gaussian_random_field()\n",
    "\n",
    "\n",
    "\n",
    "GRF_nums =  (3**2)\n",
    "offset_place_holder = np.zeros((4, GRF_nums,1))\n",
    "offset = np.apply_along_axis(GRF_wrapper, 2, offset_place_holder)\n",
    "offset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 3])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([[\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1],\n",
    "        [1,1,1],\n",
    "        [1,1,1]\n",
    "    ],\n",
    "    ]]).float()\n",
    "x.shape\n",
    "# (x - x.mean([2, 3])) / x.std([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x[:]\u001b[39m-\u001b[39;49mx\u001b[39m.\u001b[39;49mmean([\u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "x[:]-x.mean([2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.5000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(torch.tensor([\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9]\n",
    "    ]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.5000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(torch.tensor([1,2,3,4,5,6,7,8,9]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x after conv shape  torch.Size([64, 3, 244, 244])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (244) must match the size of tensor b (3) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mx after conv shape \u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m transform_norm \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m      5\u001b[0m     transforms\u001b[39m.\u001b[39mNormalize(x\u001b[39m.\u001b[39mmean([\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), x\u001b[39m.\u001b[39mstd([\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]))\n\u001b[1;32m      6\u001b[0m ])\n\u001b[0;32m----> 7\u001b[0m x \u001b[39m=\u001b[39m transform_norm(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, tensor: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnormalize(tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    361\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be Tensor Image. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tensor)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mnormalize(tensor, mean\u001b[39m=\u001b[39;49mmean, std\u001b[39m=\u001b[39;49mstd, inplace\u001b[39m=\u001b[39;49minplace)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py:928\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[39mif\u001b[39;00m std\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    927\u001b[0m     std \u001b[39m=\u001b[39m std\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 928\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49msub_(mean)\u001b[39m.\u001b[39mdiv_(std)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (244) must match the size of tensor b (3) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "x = torch.rand([64,3, 244, 244])\n",
    "print(\"x after conv shape \", x.shape)\n",
    "transform_norm = transforms.Compose([\n",
    "    transforms.Normalize(x.mean([2, 3]), x.std([2, 3]))\n",
    "])\n",
    "x = transform_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(dim=[2, 3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
